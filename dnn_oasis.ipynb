{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "import os\n",
    "%matplotlib inline\n",
    "#plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,FunctionTransformer,StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold,StratifiedShuffleSplit, train_test_split, learning_curve,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, roc_curve\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "rnd_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "sqluser = 'maxim'\n",
    "dbname = 'maxim'\n",
    "schema_name = 'mimiciii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "connect = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cursor = connect.cursor()\n",
    "cursor.execute('SET search_path to {}'.format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the query from file\n",
    "query='SELECT * FROM OASIS'\n",
    "oasis = pd.read_sql_query(query, connect)\n",
    "oasis = oasis.dropna(axis=0)\n",
    "oasis = oasis.loc[(oasis.urineoutput < 20000) & (oasis.urineoutput > 0) & \n",
    "                  (oasis.temp > 30) & (oasis.temp < 45) & (oasis.icustay_age_group == 'adult')]\n",
    "oasis['preiculos_hours'] = oasis.preiculos.dt.total_seconds()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>icustay_age_group</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>icustay_expire_flag</th>\n",
       "      <th>oasis</th>\n",
       "      <th>oasis_prob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_score</th>\n",
       "      <th>preiculos</th>\n",
       "      <th>preiculos_score</th>\n",
       "      <th>gcs</th>\n",
       "      <th>gcs_score</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>heartrate_score</th>\n",
       "      <th>meanbp</th>\n",
       "      <th>meanbp_score</th>\n",
       "      <th>resprate</th>\n",
       "      <th>resprate_score</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_score</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>urineoutput_score</th>\n",
       "      <th>mechvent</th>\n",
       "      <th>mechvent_score</th>\n",
       "      <th>electivesurgery</th>\n",
       "      <th>electivesurgery_score</th>\n",
       "      <th>preiculos_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55973</td>\n",
       "      <td>152234</td>\n",
       "      <td>200001</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.305849</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7 days 03:02:12</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.388889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>171.036667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27513</td>\n",
       "      <td>163557</td>\n",
       "      <td>200003</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.152892</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days 02:48:04</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.388889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.801111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10950</td>\n",
       "      <td>189514</td>\n",
       "      <td>200006</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.109623</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0 days 00:01:14</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.166666</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.020556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20707</td>\n",
       "      <td>129310</td>\n",
       "      <td>200007</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.054187</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days 00:01:37</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.666698</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.388889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.026944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29904</td>\n",
       "      <td>129607</td>\n",
       "      <td>200009</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.048012</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1 days +23:49:32</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.174444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  icustay_id icustay_age_group  hospital_expire_flag  \\\n",
       "0       55973   152234      200001             adult                     0   \n",
       "1       27513   163557      200003             adult                     0   \n",
       "2       10950   189514      200006             adult                     0   \n",
       "3       20707   129310      200007             adult                     0   \n",
       "4       29904   129607      200009             adult                     0   \n",
       "\n",
       "   icustay_expire_flag  oasis  oasis_prob   age  age_score         preiculos  \\\n",
       "0                    0     42    0.305849  61.0          6   7 days 03:02:12   \n",
       "1                    0     35    0.152892  48.0          3   0 days 02:48:04   \n",
       "2                    0     32    0.109623  54.0          6   0 days 00:01:14   \n",
       "3                    0     26    0.054187  43.0          3   0 days 00:01:37   \n",
       "4                    0     25    0.048012  47.0          3 -1 days +23:49:32   \n",
       "\n",
       "   preiculos_score   gcs  gcs_score  heartrate  heartrate_score      meanbp  \\\n",
       "0                1  14.0        3.0      134.0              6.0   60.000000   \n",
       "1                3  15.0        0.0      122.0              3.0  179.000000   \n",
       "2                5  15.0        0.0       73.0              0.0   61.000000   \n",
       "3                5  15.0        0.0      104.0              1.0   50.666698   \n",
       "4                5  15.0        0.0      106.0              1.0   60.000000   \n",
       "\n",
       "   meanbp_score  resprate  resprate_score       temp  temp_score  urineoutput  \\\n",
       "0           2.0      32.0             6.0  36.388889         2.0        250.0   \n",
       "1           3.0      39.0             6.0  36.388889         2.0       3652.0   \n",
       "2           2.0      27.0             1.0  36.166666         2.0       1955.0   \n",
       "3           3.0      29.0             1.0  36.388889         2.0       1295.0   \n",
       "4           2.0      17.5             0.0  34.599998         4.0       1570.0   \n",
       "\n",
       "   urineoutput_score  mechvent  mechvent_score  electivesurgery  \\\n",
       "0               10.0         0               0                0   \n",
       "1                0.0         1               9                0   \n",
       "2                1.0         1               9                0   \n",
       "3                5.0         0               0                0   \n",
       "4                1.0         1               9                1   \n",
       "\n",
       "   electivesurgery_score  preiculos_hours  \n",
       "0                      6       171.036667  \n",
       "1                      6         2.801111  \n",
       "2                      6         0.020556  \n",
       "3                      6         0.026944  \n",
       "4                      0        -0.174444  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oasis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = oasis_adults.drop(['subject_id', 'hadm_id', 'icustay_id', 'icustay_age_group', 'hospital_expire_flag',\n",
    "#                       'icustay_expire_flag', 'oasis', 'oasis_prob', 'age_prob'], axis=1)\n",
    "num_features = ['age', 'preiculos_hours', 'gcs', 'heartrate', 'meanbp', 'resprate', 'temp', 'urineoutput']\n",
    "cat_features = ['mechvent', 'electivesurgery']\n",
    "X = oasis[num_features + cat_features]\n",
    "#y = oasis.icustay_expire_flag\n",
    "y = oasis.hospital_expire_flag\n",
    "X_train_orig, X_test_orig, y_train, y_test = train_test_split(X, y, test_size=0.2, \\\n",
    "                                                    shuffle=True, stratify=y, random_state=rnd_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (38797, 10)\n",
      "Shape of test set: (9700, 10)\n",
      "Number of positives in training set: 4480\n",
      "Number of positives in test set: 1120\n"
     ]
    }
   ],
   "source": [
    "print('Shape of training set: {}'.format(X_train_orig.shape))\n",
    "print('Shape of test set: {}'.format(X_test_orig.shape))\n",
    "print('Number of positives in training set: {}'.format(y_train.sum()))\n",
    "print('Number of positives in test set: {}'.format(y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_impute = ('num_impute', SimpleImputer(missing_values=np.nan, strategy='median'))\n",
    "scale = ('scale', MinMaxScaler())\n",
    "num_transformer = Pipeline([num_impute, scale])\n",
    "\n",
    "cat_impute = ('cat_impute', SimpleImputer(strategy='constant', fill_value=2))\n",
    "#onehot = ('onehot', OneHotEncoder(handle_unknown='error'))\n",
    "cat_transformer = Pipeline(steps=[cat_impute])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train_orig)\n",
    "X_test = preprocessor.transform(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class Dataset(data.Dataset):\n",
    "    \n",
    "  def __init__(self, X, y):\n",
    "        'Initialization'\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain training indices that will be used for validation\n",
    "num_train = len(X_train)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(Dataset(X_train,y_train.values), batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(Dataset(X_train,y_train.values), batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(Dataset(X_test,y_test.values), batch_size=batch_size, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # number of hidden nodes in each layer (10)\n",
    "        hidden_1 = 128\n",
    "        # linear layer (10 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(10, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, 1)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 10)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = x.view(-1, 1)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # number of hidden nodes in each layer (10)\n",
    "        hidden = 256\n",
    "        # linear layer (10 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(10, hidden)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        # linear layer (n_hidden -> 1)\n",
    "        self.fc4 = nn.Linear(hidden, 1)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 10)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add output layer\n",
    "        x = self.fc4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = x.view(-1, 1)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.498792 \tValidation Loss: 0.120103\n",
      "Validation loss decreased (inf --> 0.120103).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.461771 \tValidation Loss: 0.111797\n",
      "Validation loss decreased (0.120103 --> 0.111797).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.450467 \tValidation Loss: 0.111022\n",
      "Validation loss decreased (0.111797 --> 0.111022).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.442393 \tValidation Loss: 0.110829\n",
      "Validation loss decreased (0.111022 --> 0.110829).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.437578 \tValidation Loss: 0.108793\n",
      "Validation loss decreased (0.110829 --> 0.108793).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.434813 \tValidation Loss: 0.107968\n",
      "Validation loss decreased (0.108793 --> 0.107968).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.435212 \tValidation Loss: 0.108048\n",
      "Epoch: 8 \tTraining Loss: 0.436272 \tValidation Loss: 0.110035\n",
      "Epoch: 9 \tTraining Loss: 0.432894 \tValidation Loss: 0.106762\n",
      "Validation loss decreased (0.107968 --> 0.106762).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.427700 \tValidation Loss: 0.107414\n",
      "Epoch: 11 \tTraining Loss: 0.421973 \tValidation Loss: 0.109692\n",
      "Epoch: 12 \tTraining Loss: 0.426531 \tValidation Loss: 0.106771\n",
      "Epoch: 13 \tTraining Loss: 0.426004 \tValidation Loss: 0.108145\n",
      "Epoch: 14 \tTraining Loss: 0.420294 \tValidation Loss: 0.107217\n",
      "Epoch: 15 \tTraining Loss: 0.421216 \tValidation Loss: 0.106786\n",
      "Epoch: 16 \tTraining Loss: 0.417804 \tValidation Loss: 0.106354\n",
      "Validation loss decreased (0.106762 --> 0.106354).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.420613 \tValidation Loss: 0.104739\n",
      "Validation loss decreased (0.106354 --> 0.104739).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.418174 \tValidation Loss: 0.105046\n",
      "Epoch: 19 \tTraining Loss: 0.415733 \tValidation Loss: 0.106154\n",
      "Epoch: 20 \tTraining Loss: 0.413160 \tValidation Loss: 0.104807\n",
      "Epoch: 21 \tTraining Loss: 0.415898 \tValidation Loss: 0.104273\n",
      "Validation loss decreased (0.104739 --> 0.104273).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.414872 \tValidation Loss: 0.105371\n",
      "Epoch: 23 \tTraining Loss: 0.407490 \tValidation Loss: 0.108800\n",
      "Epoch: 24 \tTraining Loss: 0.414057 \tValidation Loss: 0.102642\n",
      "Validation loss decreased (0.104273 --> 0.102642).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.414344 \tValidation Loss: 0.104254\n",
      "Epoch: 26 \tTraining Loss: 0.413225 \tValidation Loss: 0.101299\n",
      "Validation loss decreased (0.102642 --> 0.101299).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.410251 \tValidation Loss: 0.101099\n",
      "Validation loss decreased (0.101299 --> 0.101099).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.411629 \tValidation Loss: 0.103069\n",
      "Epoch: 29 \tTraining Loss: 0.408663 \tValidation Loss: 0.104392\n",
      "Epoch: 30 \tTraining Loss: 0.409692 \tValidation Loss: 0.108964\n",
      "Epoch: 31 \tTraining Loss: 0.410797 \tValidation Loss: 0.107998\n",
      "Epoch: 32 \tTraining Loss: 0.407692 \tValidation Loss: 0.107298\n",
      "Epoch: 33 \tTraining Loss: 0.412682 \tValidation Loss: 0.107641\n",
      "Epoch: 34 \tTraining Loss: 0.406451 \tValidation Loss: 0.105921\n",
      "Epoch: 35 \tTraining Loss: 0.407456 \tValidation Loss: 0.103488\n",
      "Epoch: 36 \tTraining Loss: 0.407314 \tValidation Loss: 0.104948\n",
      "Epoch: 37 \tTraining Loss: 0.411560 \tValidation Loss: 0.100858\n",
      "Validation loss decreased (0.101099 --> 0.100858).  Saving model ...\n",
      "Epoch: 38 \tTraining Loss: 0.403429 \tValidation Loss: 0.105447\n",
      "Epoch: 39 \tTraining Loss: 0.408102 \tValidation Loss: 0.103119\n",
      "Epoch: 40 \tTraining Loss: 0.407741 \tValidation Loss: 0.104451\n",
      "Epoch: 41 \tTraining Loss: 0.407217 \tValidation Loss: 0.103126\n",
      "Epoch: 42 \tTraining Loss: 0.401955 \tValidation Loss: 0.104620\n",
      "Epoch: 43 \tTraining Loss: 0.402846 \tValidation Loss: 0.103059\n",
      "Epoch: 44 \tTraining Loss: 0.405060 \tValidation Loss: 0.107179\n",
      "Epoch: 45 \tTraining Loss: 0.405864 \tValidation Loss: 0.103526\n",
      "Epoch: 46 \tTraining Loss: 0.405804 \tValidation Loss: 0.107073\n",
      "Epoch: 47 \tTraining Loss: 0.406557 \tValidation Loss: 0.105307\n",
      "Epoch: 48 \tTraining Loss: 0.401357 \tValidation Loss: 0.102391\n",
      "Epoch: 49 \tTraining Loss: 0.403838 \tValidation Loss: 0.104731\n",
      "Epoch: 50 \tTraining Loss: 0.407893 \tValidation Loss: 0.105880\n",
      "Epoch: 51 \tTraining Loss: 0.403969 \tValidation Loss: 0.103739\n",
      "Epoch: 52 \tTraining Loss: 0.400958 \tValidation Loss: 0.104811\n",
      "Epoch: 53 \tTraining Loss: 0.402908 \tValidation Loss: 0.106535\n",
      "Epoch: 54 \tTraining Loss: 0.405214 \tValidation Loss: 0.104948\n",
      "Epoch: 55 \tTraining Loss: 0.400080 \tValidation Loss: 0.106482\n",
      "Epoch: 56 \tTraining Loss: 0.404081 \tValidation Loss: 0.104330\n",
      "Epoch: 57 \tTraining Loss: 0.401032 \tValidation Loss: 0.104514\n",
      "Epoch: 58 \tTraining Loss: 0.403484 \tValidation Loss: 0.103225\n",
      "Epoch: 59 \tTraining Loss: 0.403677 \tValidation Loss: 0.104536\n",
      "Epoch: 60 \tTraining Loss: 0.402353 \tValidation Loss: 0.104784\n",
      "Epoch: 61 \tTraining Loss: 0.401912 \tValidation Loss: 0.102756\n",
      "Epoch: 62 \tTraining Loss: 0.399006 \tValidation Loss: 0.105415\n",
      "Epoch: 63 \tTraining Loss: 0.401872 \tValidation Loss: 0.103321\n",
      "Epoch: 64 \tTraining Loss: 0.402551 \tValidation Loss: 0.106223\n",
      "Epoch: 65 \tTraining Loss: 0.398854 \tValidation Loss: 0.103760\n",
      "Epoch: 66 \tTraining Loss: 0.402709 \tValidation Loss: 0.103986\n",
      "Epoch: 67 \tTraining Loss: 0.399283 \tValidation Loss: 0.103607\n",
      "Epoch: 68 \tTraining Loss: 0.405524 \tValidation Loss: 0.102833\n",
      "Epoch: 69 \tTraining Loss: 0.398100 \tValidation Loss: 0.102040\n",
      "Epoch: 70 \tTraining Loss: 0.401847 \tValidation Loss: 0.103563\n",
      "Epoch: 71 \tTraining Loss: 0.400477 \tValidation Loss: 0.103118\n",
      "Epoch: 72 \tTraining Loss: 0.398193 \tValidation Loss: 0.104179\n",
      "Epoch: 73 \tTraining Loss: 0.400376 \tValidation Loss: 0.107539\n",
      "Epoch: 74 \tTraining Loss: 0.401500 \tValidation Loss: 0.102808\n",
      "Epoch: 75 \tTraining Loss: 0.405005 \tValidation Loss: 0.102451\n",
      "Epoch: 76 \tTraining Loss: 0.398485 \tValidation Loss: 0.103009\n",
      "Epoch: 77 \tTraining Loss: 0.394214 \tValidation Loss: 0.102148\n",
      "Epoch: 78 \tTraining Loss: 0.400105 \tValidation Loss: 0.103340\n",
      "Epoch: 79 \tTraining Loss: 0.397923 \tValidation Loss: 0.104052\n",
      "Epoch: 80 \tTraining Loss: 0.395003 \tValidation Loss: 0.103051\n",
      "Epoch: 81 \tTraining Loss: 0.398456 \tValidation Loss: 0.102471\n",
      "Epoch: 82 \tTraining Loss: 0.394488 \tValidation Loss: 0.103893\n",
      "Epoch: 83 \tTraining Loss: 0.395684 \tValidation Loss: 0.104434\n",
      "Epoch: 84 \tTraining Loss: 0.399384 \tValidation Loss: 0.102456\n",
      "Epoch: 85 \tTraining Loss: 0.395490 \tValidation Loss: 0.103444\n",
      "Epoch: 86 \tTraining Loss: 0.392636 \tValidation Loss: 0.101895\n",
      "Epoch: 87 \tTraining Loss: 0.393293 \tValidation Loss: 0.104348\n",
      "Epoch: 88 \tTraining Loss: 0.396495 \tValidation Loss: 0.101956\n",
      "Epoch: 89 \tTraining Loss: 0.398271 \tValidation Loss: 0.102809\n",
      "Epoch: 90 \tTraining Loss: 0.398665 \tValidation Loss: 0.105035\n",
      "Epoch: 91 \tTraining Loss: 0.402995 \tValidation Loss: 0.104554\n",
      "Epoch: 92 \tTraining Loss: 0.395682 \tValidation Loss: 0.102609\n",
      "Epoch: 93 \tTraining Loss: 0.394630 \tValidation Loss: 0.100487\n",
      "Validation loss decreased (0.100858 --> 0.100487).  Saving model ...\n",
      "Epoch: 94 \tTraining Loss: 0.398556 \tValidation Loss: 0.100903\n",
      "Epoch: 95 \tTraining Loss: 0.393412 \tValidation Loss: 0.102812\n",
      "Epoch: 96 \tTraining Loss: 0.394402 \tValidation Loss: 0.103899\n",
      "Epoch: 97 \tTraining Loss: 0.395652 \tValidation Loss: 0.107694\n",
      "Epoch: 98 \tTraining Loss: 0.392793 \tValidation Loss: 0.105162\n",
      "Epoch: 99 \tTraining Loss: 0.399100 \tValidation Loss: 0.104617\n",
      "Epoch: 100 \tTraining Loss: 0.394296 \tValidation Loss: 0.104142\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data.float())\n",
    "        # calculate the loss\n",
    "        target = target.view(-1,1)\n",
    "        weight=compute_sample_weight(class_weight='balanced', y=target)\n",
    "        weight=torch.Tensor(weight)\n",
    "        weight=weight.view(-1,1)\n",
    "        criterion.weight = weight\n",
    "        loss = criterion(output.float(), target.float())\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, target in valid_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data.float())\n",
    "        # calculate the loss\n",
    "        target = target.view(-1,1)\n",
    "        weight=compute_sample_weight(class_weight='balanced', y=target)\n",
    "        weight=torch.Tensor(weight)\n",
    "        weight=weight.view(-1,1)\n",
    "        criterion.weight = weight\n",
    "        loss = criterion(output.float(), target.float())\n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval() # prep model for evaluation\n",
    "test_loss = 0.0\n",
    "predictions = []\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data.float())\n",
    "    # calculate the loss\n",
    "    #target = target.view(-1,1)\n",
    "    #loss = criterion(output.float(), target.float())\n",
    "    # update test loss \n",
    "    #test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    #_, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    #predictions += pred\n",
    "    predictions += output.view(1,-1).tolist()[0]\n",
    "    #predictions += output.tolist()\n",
    "    #correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    #for i in range(batch_size):\n",
    "    #    label = target.data[i]\n",
    "    #    class_correct[label] += correct[i].item()\n",
    "    #    class_total[label] += 1\n",
    "binary_predictions = np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET f1: 0.40 auroc: 0.82 precision: 0.28 recall: 0.69\n"
     ]
    }
   ],
   "source": [
    "F1 = f1_score(y_test, binary_predictions)\n",
    "auroc = roc_auc_score(y_test, predictions)\n",
    "precision = precision_score(y_test, binary_predictions)\n",
    "recall = recall_score(y_test, binary_predictions)\n",
    "res = 'TEST SET f1: {0:.2f} auroc: {1:.2f} precision: {2:.2f} recall: {3:.2f}'.format(F1,auroc,precision,recall)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
